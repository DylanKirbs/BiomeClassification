{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify the GeoTif data from WorldClim"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation and setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System imports\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some print utilities to make output more digestible\n",
    "from utilities.printUtils import cPrint, hPrint\n",
    "from utilities.printUtils import AnsiColours as Cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Utilities\n",
    "from data.WCDownloader import downloadData, extractData\n",
    "from data.dataUtils import DB\n",
    "\n",
    "def downloadFileList(files: list[str], resolution:str, dataPath: str = \"./data\") -> None:\n",
    "    \"\"\"\n",
    "    Checks for and downloads any necessary files from the list.\n",
    "\n",
    "    The files will be downloaded and extracted into directories in the data directory with their respective name and resolution.\n",
    "\n",
    "    The file list should simply contain the WC variable names.\n",
    "    For example:\n",
    "        `files = ['tavg','prec']`\n",
    "\n",
    "    Args:\n",
    "        files (list[str]): The list of files.\n",
    "        resolution (str): The resolution of the files.\n",
    "        dataPath (str, optional): The data directory. Defaults to \"./data\".\n",
    "    \"\"\"\n",
    "\n",
    "    cPrint(f\"Checking for required files.\", Cols.BLUE)\n",
    "\n",
    "    # Check for the directory\n",
    "    if not os.path.isdir(dataPath):\n",
    "        cPrint(\"Creating data directory.\", Cols.YELLOW)\n",
    "        os.makedirs(dataPath)\n",
    "\n",
    "    # Check for the files\n",
    "    for file in files:\n",
    "        if not os.path.isdir(f\"{dataPath}/{file}_{resolution}\"):\n",
    "            cPrint(\n",
    "                f\"{file}_{resolution} directory not found. Checking for zip file.\", Cols.YELLOW)\n",
    "\n",
    "            # Check for the zip file\n",
    "            if not os.path.isfile(f\"{dataPath}/{file}_{resolution}.zip\"):\n",
    "                cPrint(\n",
    "                    f\"{file}_{resolution}.zip not found. Downloading.\", Cols.YELLOW)\n",
    "                downloadData(file, resolution, dataPath)\n",
    "                cPrint(f\"{file}_{resolution}.zip downloaded.\",\n",
    "                       Cols.GREEN)\n",
    "\n",
    "            # Extract the zip file\n",
    "            extractData(file, resolution, dataPath)\n",
    "            cPrint(f\"{file}_{resolution}.zip extracted.\", Cols.GREEN)\n",
    "        else:\n",
    "            cPrint(f\"{file}_{resolution} directory found.\", Cols.GREEN)\n",
    "\n",
    "def removeDirs(files: list[str], resolution:str, dataPath: str = \"./data\") -> None:\n",
    "    \"\"\"\n",
    "    Removes the directories for the given files and resolution.\n",
    "    The .zip files will not be removed.\n",
    "\n",
    "    Args:\n",
    "        files (list[str]): The list of files.\n",
    "        resolution (str): The resolution of the files.\n",
    "        dataPath (str, optional): The data directory. Defaults to \"./data\".\n",
    "    \"\"\"\n",
    "\n",
    "    cPrint(\"Removing directories.\", Cols.BLUE)\n",
    "\n",
    "    for file in files:\n",
    "        if os.path.isdir(f\"{dataPath}/{file}_{resolution}\"):\n",
    "            try:\n",
    "                cPrint(f\"Removing {file}_{resolution} directory.\", Cols.YELLOW)\n",
    "                shutil.rmtree(f\"{dataPath}/{file}_{resolution}\")\n",
    "            except:\n",
    "                cPrint(f\"Failed to remove {file}_{resolution} directory.\", Cols.RED)\n",
    "        else:\n",
    "            cPrint(f\"{file}_{resolution} directory not found.\", Cols.YELLOW)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise the constants needed to perform the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "REQUIRED_VARS = [\"bio\", \"tavg\", \"prec\"]\n",
    "CHUNKS = 100\n",
    "NUM_THREADS = 3\n",
    "RESOLUTION = \"5m\"\n",
    "DATA_PATH = \"./data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the database\n",
    "db = DB(f'{DATA_PATH}/data.sqlite')\n",
    "\n",
    "# Create coordinates table\n",
    "db.create_table(\"classification\", \"(id INTEGER PRIMARY KEY, lat REAL, lon REAL, climate INTEGER)\")\n",
    "db.create_table(f\"bio_{RESOLUTION}\", \"(id INTEGER PRIMARY KEY, lat REAL, lon REAL, bio1 REAL, bio2 REAL, bio3 REAL, bio4 REAL, bio5 REAL, bio6 REAL, bio7 REAL, bio8 REAL, bio9 REAL, bio10 REAL, bio11 REAL, bio12 REAL, bio13 REAL, bio14 REAL, bio15 REAL, bio16 REAL, bio17 REAL, bio18 REAL, bio19 REAL)\")\n",
    "db.create_table(f\"tavg_{RESOLUTION}\", \"(id INTEGER PRIMARY KEY, lat REAL, lon REAL, jan REAL, feb REAL, mar REAL, apr REAL, may REAL, jun REAL, jul REAL, aug REAL, sep REAL, oct REAL, nov REAL, dec REAL)\")\n",
    "db.create_table(f\"prec_{RESOLUTION}\", \"(id INTEGER PRIMARY KEY, lat REAL, lon REAL, jan REAL, feb REAL, mar REAL, apr REAL, may REAL, jun REAL, jul REAL, aug REAL, sep REAL, oct REAL, nov REAL, dec REAL)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mChecking for required files.\u001b[0m\n",
      "\u001b[93mbio_5m directory not found. Checking for zip file.\u001b[0m\n",
      "\u001b[92mbio_5m.zip extracted.\u001b[0m\n",
      "\u001b[93mtavg_5m directory not found. Checking for zip file.\u001b[0m\n",
      "\u001b[92mtavg_5m.zip extracted.\u001b[0m\n",
      "\u001b[93mprec_5m directory not found. Checking for zip file.\u001b[0m\n",
      "\u001b[92mprec_5m.zip extracted.\u001b[0m\n",
      "\u001b[94mRemoving directories.\u001b[0m\n",
      "\u001b[93mRemoving bio_5m directory.\u001b[0m\n",
      "\u001b[93mRemoving tavg_5m directory.\u001b[0m\n",
      "\u001b[93mRemoving prec_5m directory.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Download the required files if they do not exist\n",
    "downloadFileList(REQUIRED_VARS, RESOLUTION, DATA_PATH)\n",
    "\n",
    "# flatten and combine the data into the database\n",
    "\"\"\"\n",
    "meta, base = geoData.get(list(geoData.keys())[0])  # type: ignore\n",
    "    data[\"lat\"] = np.repeat(base.index.values, base.shape[1])\n",
    "    data[\"lon\"] = np.tile(base.columns.values, base.shape[0])\n",
    "    data[\"classification\"] = 0  # classification values\n",
    "\n",
    "    # Thus we need to flatten the tavg and prec data into columns\n",
    "    for col in tqdm(geoData.keys(), desc=\"Flattening data\", unit=\"files\"):\n",
    "        data[col] = geoData[col][1].values.flatten()\n",
    "\"\"\"\n",
    "\n",
    "#  remove the data directories\n",
    "removeDirs(REQUIRED_VARS, RESOLUTION, DATA_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the classification data to a numpy array (like a raster)\n",
    "\"\"\"\n",
    "# Convert the classification back to a raster\n",
    "classification = classification.pivot(index=\"lat\", columns=\"lon\", values=\"classification\")\n",
    "\n",
    "# TODO: Figure out why we need to reverse the latitudes\n",
    "# We may be able to correct this when we create the lat column in the first place\n",
    "classification = classification.iloc[::-1]\n",
    "classArr = classification.to_numpy()\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
